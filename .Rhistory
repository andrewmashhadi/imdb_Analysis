#readRenviron("{INSERT PATH TO R ENVIRON FILE HERE}")                           # commenting out--change to the location of your Renviron file to force R reread Renviron instead of starting R session over
#### ====================================================================== ####
## Scrape IDs from HTML on imdb, then store in JSON
## ========================================================================== ##
library(rjson)
library(XML)
library(xtable)
library(tools)
numURLS <- 20
numMoviesPerURL <- 50
genres <- c("Action",
"Adventure",
"Animation",
"Biography",
"Comedy",
"Crime",
"Drama",
"Family",
"Fantasy",
"Film-Noir",
"History",
"Horror",
"Music",
"Musical",
"Mystery",
"Romance",
"Sci-Fi",
"Sport",
"Thriller",
"War",
"Western")
movies_by_genre <- list()
for (genre in genres) {
more_movies <- as.data.frame(matrix(nrow=numURLS*numMoviesPerURL, ncol=3))
colnames(more_movies)<-c("Name","ID", "Genre")
move_on <- FALSE
for (iURL in 1:20) {
URL <- paste0("https://www.imdb.com/search/title/?title_type=feature&num_votes=25000,",
"&genres=",
genre,
"&start=",
(iURL-1)*numMoviesPerURL + 1)
cat("Collecting at:", URL, "\n")
xxhtml <-
readLines(URL)
this_parsed_page <- htmlParse(xxhtml)
for (i in 1:50){
xpath <- paste0("/html/body/div[2]/div/div[2]/div/div[1]/div/div[3]/div/div[", i, "]/div[3]/h3/a")
xxa <- getNodeSet(this_parsed_page, xpath)
mname <- xmlValue(xxa, "a")
m_id <- try(xmlSApply(xxa, xmlGetAttr, "href"), silent = TRUE)
more_movies$Name[(iURL-1)*numMoviesPerURL + i] <- mname
more_movies$ID[(iURL-1)*numMoviesPerURL + i] <- substr(m_id, 8, 16)
more_movies$Genre[[(iURL-1)*numMoviesPerURL + i]] <- genre
if( "try-error" %in% class(m_id) ) {
cat("Filled max movies in: ", genre, " genre")
more_movies <- more_movies[-(((iURL-1)*numMoviesPerURL+i+1):1000), ]
move_on <- TRUE
break
} else {
cat("Movie ID found: ", mname, "\n")
}
}
if (move_on){
break
}
}
movies_by_genre[[genre]] <- more_movies
}
movie_data <- toJSON(movies_by_genre)
writeLines(movie_data, file.path("imdb_data", "movies_by_genre", "movies_by_genre.json"))
#### ====================================================================== ####
## Use IDs with imdb-API to extract details (DONT-RUN WITHOUT ASKING ANDREW)
## ========================================================================== ##
## define parameters
xpath_main_data <- Sys.getenv("PATH_MY_MAIN_DATA")
ximdb_api_key <- Sys.getenv("IMDB_API_KEY")
xpath_details <- file.path(xpath_main_data, "imdb_data", "more_details")
## get previous IDs so to not extract data again
xlt <- list.files(xpath_details)
ids <- as.character(lapply(lapply(lapply(xlt, strsplit, "_"), "[[", 1), "[", 1))
movie_data <- fromJSON(readLines(file.path("imdb_data", "movies_by_genre", "movies_by_genre.json")))
# not length(movie_data) here bc 5k limit for api (need to run 6-length(movie_data))
k <- 0
#### ====================================================================== ####
## Purpose: Scrapes imdb lists for movie IDs and stores in JSON file to be used
##          later if we need more data
## Author: Andrew Mashhadi
## ========================================================================== ##
#### ====================================================================== ####
## Main
## ========================================================================== ##
## read Renviron file
#readRenviron("{INSERT PATH TO R ENVIRON FILE HERE}")                           # commenting out--change to the location of your Renviron file to force R reread Renviron instead of starting R session over
#### ====================================================================== ####
## Scrape IDs from HTML on imdb, then store in JSON
## ========================================================================== ##
library(rjson)
library(XML)
library(xtable)
library(tools)
numURLS <- 20
numMoviesPerURL <- 50
genres <- c("Action",
"Adventure",
"Animation",
"Biography",
"Comedy",
"Crime",
"Drama",
"Family",
"Fantasy",
"Film-Noir",
"History",
"Horror",
"Music",
"Musical",
"Mystery",
"Romance",
"Sci-Fi",
"Sport",
"Thriller",
"War",
"Western")
movies_by_genre <- list()
for (genre in genres) {
more_movies <- as.data.frame(matrix(nrow=numURLS*numMoviesPerURL, ncol=3))
colnames(more_movies)<-c("Name","ID", "Genre")
move_on <- FALSE
for (iURL in 1:20) {
URL <- paste0("https://www.imdb.com/search/title/?title_type=feature&num_votes=25000,",
"&genres=",
genre,
"&start=",
(iURL-1)*numMoviesPerURL + 1)
cat("Collecting at:", URL, "\n")
xxhtml <-
readLines(URL)
this_parsed_page <- htmlParse(xxhtml)
for (i in 1:50){
xpath <- paste0("/html/body/div[2]/div/div[2]/div/div[1]/div/div[3]/div/div[", i, "]/div[3]/h3/a")
xxa <- getNodeSet(this_parsed_page, xpath)
mname <- xmlValue(xxa, "a")
m_id <- try(xmlSApply(xxa, xmlGetAttr, "href"), silent = TRUE)
more_movies$Name[(iURL-1)*numMoviesPerURL + i] <- mname
more_movies$ID[(iURL-1)*numMoviesPerURL + i] <- substr(m_id, 8, 16)
more_movies$Genre[[(iURL-1)*numMoviesPerURL + i]] <- genre
if( "try-error" %in% class(m_id) ) {
cat("Filled max movies in: ", genre, " genre")
more_movies <- more_movies[-(((iURL-1)*numMoviesPerURL+i+1):1000), ]
move_on <- TRUE
break
} else {
cat("Movie ID found: ", mname, "\n")
}
}
if (move_on){
break
}
}
movies_by_genre[[genre]] <- more_movies
}
movie_data <- toJSON(movies_by_genre)
writeLines(movie_data, file.path("imdb_data", "movies_by_genre", "movies_by_genre.json"))
## define parameters
xpath_main_data <- Sys.getenv("PATH_MY_MAIN_DATA")
ximdb_api_key <- Sys.getenv("IMDB_API_KEY")
xpath_details <- file.path(xpath_main_data, "imdb_data", "more_details")
## get previous IDs so to not extract data again
xlt <- list.files(xpath_details)
ids <- as.character(lapply(lapply(lapply(xlt, strsplit, "_"), "[[", 1), "[", 1))
movie_data <- fromJSON(readLines(file.path("imdb_data", "movies_by_genre", "movies_by_genre.json")))
ids
view(as.data.frame(ids))
lll <- as.data.frame(ids)
View(lll)
for (genre in 6:11){
g_df <- as.data.frame(movie_data[[genre]])
for (i in 1:nrow(g_df)) {
id <- g_df$ID[i]
title <- g_df$Name[i]
if (id %in% ids){
cat("Already have details for ", title, "\n")
}
else{
xxInfo <-
try(
readLines( paste0("https://imdb-api.com/en/API/Title/", ximdb_api_key, "/", id) ),
silent=TRUE
)
k <- k + 1
xfn <- paste0(id, "_data", ".json");
writeLines( xxInfo, file.path( xpath_details, xfn ) )
xbool_keep_going <- FALSE
cat("Got details for ", title, "\n")
ids <- c(ids, id)
Sys.sleep(1)
}
}
}
k <- 0
for (genre in 6:11){
g_df <- as.data.frame(movie_data[[genre]])
for (i in 1:nrow(g_df)) {
id <- g_df$ID[i]
title <- g_df$Name[i]
if (id %in% ids){
cat("Already have details for ", title, "\n")
}
else{
xxInfo <-
try(
readLines( paste0("https://imdb-api.com/en/API/Title/", ximdb_api_key, "/", id) ),
silent=TRUE
)
k <- k + 1
xfn <- paste0(id, "_data", ".json");
writeLines( xxInfo, file.path( xpath_details, xfn ) )
xbool_keep_going <- FALSE
cat("Got details for ", title, "\n")
ids <- c(ids, id)
Sys.sleep(1)
}
}
}
k <- 0
for (genre in 6:11){
g_df <- as.data.frame(movie_data[[genre]])
for (i in 1:nrow(g_df)) {
id <- g_df$ID[i]
title <- g_df$Name[i]
if (id %in% ids){
cat("Already have details for ", title, "\n")
}
else{
xxInfo <-
try(
readLines( paste0("https://imdb-api.com/en/API/Title/", ximdb_api_key, "/", id) ),
silent=TRUE
)
k <- k + 1
xfn <- paste0(id, "_data", ".json");
writeLines( xxInfo, file.path( xpath_details, xfn ) )
xbool_keep_going <- FALSE
cat("Got details for ", title, "\n")
ids <- c(ids, id)
#Sys.sleep(1)
}
}
}
length(movie_data)
for (genre in 12:16){
g_df <- as.data.frame(movie_data[[genre]])
for (i in 1:nrow(g_df)) {
id <- g_df$ID[i]
title <- g_df$Name[i]
if (id %in% ids){
cat("Already have details for ", title, "\n")
}
else{
xxInfo <-
try(
readLines( paste0("https://imdb-api.com/en/API/Title/", ximdb_api_key, "/", id) ),
silent=TRUE
)
k <- k + 1
xfn <- paste0(id, "_data", ".json");
writeLines( xxInfo, file.path( xpath_details, xfn ) )
xbool_keep_going <- FALSE
cat("Got details for ", title, "\n")
ids <- c(ids, id)
#Sys.sleep(1)
}
}
}
length(movie_data)
for (genre in 17:19){
g_df <- as.data.frame(movie_data[[genre]])
for (i in 1:nrow(g_df)) {
id <- g_df$ID[i]
title <- g_df$Name[i]
if (id %in% ids){
cat("Already have details for ", title, "\n")
}
else{
xxInfo <-
try(
readLines( paste0("https://imdb-api.com/en/API/Title/", ximdb_api_key, "/", id) ),
silent=TRUE
)
k <- k + 1
xfn <- paste0(id, "_data", ".json");
writeLines( xxInfo, file.path( xpath_details, xfn ) )
xbool_keep_going <- FALSE
cat("Got details for ", title, "\n")
ids <- c(ids, id)
#Sys.sleep(1)
}
}
}
for (genre in 20:21){
g_df <- as.data.frame(movie_data[[genre]])
for (i in 1:nrow(g_df)) {
id <- g_df$ID[i]
title <- g_df$Name[i]
if (id %in% ids){
cat("Already have details for ", title, "\n")
}
else{
xxInfo <-
try(
readLines( paste0("https://imdb-api.com/en/API/Title/", ximdb_api_key, "/", id) ),
silent=TRUE
)
k <- k + 1
xfn <- paste0(id, "_data", ".json");
writeLines( xxInfo, file.path( xpath_details, xfn ) )
xbool_keep_going <- FALSE
cat("Got details for ", title, "\n")
ids <- c(ids, id)
#Sys.sleep(1)
}
}
}
length(movie_data)
# not length(movie_data) here bc 5k limit for api (need to run 6-length(movie_data))
k <- 0
for (genre in 1:length(movie_data)){
g_df <- as.data.frame(movie_data[[genre]])
for (i in 1:nrow(g_df)) {
id <- g_df$ID[i]
title <- g_df$Name[i]
if (id %in% ids){
cat("Already have details for ", title, "\n")
}
else{
xxInfo <-
try(
readLines( paste0("https://imdb-api.com/en/API/Title/", ximdb_api_key, "/", id) ),
silent=TRUE
)
k <- k + 1
xfn <- paste0(id, "_data", ".json");
writeLines( xxInfo, file.path( xpath_details, xfn ) )
xbool_keep_going <- FALSE
cat("Got details for ", title, "\n")
ids <- c(ids, id)
#Sys.sleep(1)
}
}
}
#### ====================================================================== ####
## Purpose: MOVE SCRAPED JSON DATA TO MYSQL DATABASE
## Author: Dylan Jorling
## ========================================================================== ##
#### ====================================================================== ####
## Set up parameters
## ========================================================================== ##
## read Renviron file
#readRenviron("{INSERT PATH TO R ENVIRON FILE HERE}")                           # commenting out--change to the location of your Renviron file to force R reread Renviron instead of starting R session over
## libraries
library(RMySQL)
library(rjson)
library(readr)
library(stringr)
## parameters
xpath_main_data <- Sys.getenv("PATH_MY_MAIN_DATA")
## change path to where your json files located
xpath_details <- file.path(xpath_main_data, "imdb_data", "more_details")
## connect to my database
drv <- dbDriver("MySQL")
xdbsock <- ""
xdbuser <- Sys.getenv("MAS405_AWS_MY_DB_ADMIN_USER")
xpw     <- Sys.getenv("MAS405_AWS_MY_DB_ADMIN_PW")
xdbname <- Sys.getenv("MAS405_AWS_MY_DB_ADMIN_DBNAME")
xdbhost <- Sys.getenv("MAS405_AWS_MY_DB_ADMIN_HOST")
xdbport <- as.integer( Sys.getenv("MAS405_AWS_MY_DB_ADMIN_PORT") )
con <-
dbConnect(
drv,
user=xdbuser,
password=xpw,
dbname=xdbname,
host=xdbhost,
port=xdbport,
unix.sock=xdbsock
)
dbListTables(con)
dbGetInfo(con)
#### ====================================================================== ####
## Create extd details table
## ========================================================================== ##
options(scipen=999)
xtableName_titles <- "imdb_details_extd"
# drop table if need to redo, otherwise can comment out
# xx <- dbGetQuery(con, "DROP TABLE IF EXISTS imdb_details_extd")
xbool.tableExists <- dbExistsTable(con, xtableName_titles) ; xbool.tableExists
if(!xbool.tableExists) {
qstr <-
paste0(
"CREATE TABLE ", xtableName_titles, "  ",
"(id VARCHAR(15) NOT NULL, ",
"title TEXT, ",
"fullTitle TEXT, ",
"type VARCHAR(20), ",
"year INT(10), ",
"date INT(15), ",
"runtime INT(5), ",
"plot TEXT, ",
"awards TEXT, ",
"directors TEXT, ",
"writers TEXT, ",
"stars TEXT, ",
"genres TEXT, ",
"companies TEXT, ",
"languages TEXT, ",
"rating VARCHAR(15), ",
"imDbRatingCount INT(10), ",
"imDbRating DOUBLE, ",
"metacriticRating INT(4), ",
"budget DOUBLE, ",
"grossUSA DOUBLE, ",
"grossWorldwide DOUBLE, ",
"keywords TEXT, ",
"PRIMARY KEY (id))"
)
xx <- dbGetQuery(con, qstr)
}
#### ====================================================================== ####
## Load data into sql database
## ========================================================================== ##
file_ls <- list.files(xpath_details)
for(i in 1:length(file_ls)){
xthis_fn <- file_ls[i] ; xthis_fn
#load data
x_ls <- fromJSON( file=file.path(xpath_details, xthis_fn))
if (is.null(x_ls$title)) { next }
id <- x_ls$id
title <- gsub("'","",x_ls$title)
fullTitle <- gsub("'","",x_ls$fullTitle)
type <- x_ls$type
year <- x_ls$year
if(is.null(x_ls$releaseDate)){date <- "NULL"}
else if(x_ls$releaseDate == ""){date <- "NULL"}
else{date <- gsub("-", "", x_ls$releaseDate)}
if(is.null(x_ls$runtimeMins)){runtime <- NA} else{runtime <- as.integer(x_ls$runtimeMins)}
plot <- gsub("\"","",x_ls$plot)
plot <- gsub("'","",plot)
awards <- gsub("'","",x_ls$awards)
if(x_ls$directors == ""){directors = "NULL"} else{directors <- gsub("'","",x_ls$directors)}
if(x_ls$writers == ""){writers = "NULL"} else{writers <- gsub("'","",x_ls$writers)}
stars <- gsub("'","",x_ls$stars)
genres <- x_ls$genres
companies <- gsub("'","",x_ls$companies)
languages <- x_ls$languages
rating <- x_ls$contentRating
imdbratingcount <- x_ls$imDbRatingVotes
imdbrating <- x_ls$imDbRating
metacritic <- x_ls$metacriticRating
budget <- parse_number(x_ls$boxOffice$budget)
grossUS <- parse_number(x_ls$boxOffice$grossUSA)
if(is.na(grossUS)){grossUS = NULL}
grossworld <- parse_number(x_ls$boxOffice$cumulativeWorldwideGross)
keywords <- x_ls$keywords
xx <- dbGetQuery(con, paste0("SELECT id FROM ", xtableName_titles, " WHERE id='", id, "'"))
if( nrow(xx) == 0 ){
qstr <-
paste0(
"INSERT INTO ", xtableName_titles, " (id, title, fullTitle,",
" type, year, date, runtime, plot, awards, directors, writers,",
" stars, genres, companies, languages, rating, imDbRatingCount,",
" imDbRating, metacriticRating, budget, grossUSA, grossWorldwide,",
" keywords) ",
" VALUES ",
"('",
id, "', '",
title, "', '",
fullTitle, "', '",
type, "', ",
as.integer(year), ", ",
date, ", ",
if(is.na(runtime)){"NULL"} else{runtime}, ", '",
plot, "', '",
awards, "', '",
directors, "', '",
writers, "', '",
stars, "', '",
genres, "', '",
companies, "', '",
languages, "', '",
rating, "', ",
as.integer(imdbratingcount), ", ",
imdbrating, ", ",
if(is.null(metacritic)){"NULL"} else{as.integer(metacritic)}, ", ",
if(is.na(budget)){"NULL"} else{budget}, ", ",
if(is.null(grossUS)){"NULL"} else{grossUS}, ", ",
if(is.na(grossworld)){"NULL"} else{grossworld}, ", '",
keywords, "')"
)
qstr
xx <- try( dbGetQuery(con, qstr), silent=TRUE )
if( "try-error" %in% class(xx) ) {
cat("SQL insert into IMDB Details Table failed for", title, "\n")
#stop() ;
} else {
cat("Successfully inserted", title, "into IMDB Details Table", "\n")
}
} else {
cat( title, "already present in IMDB Details Table", "\n")
}
}
yy <- dbGetQuery(con, "SELECT * FROM imdb_details_extd")
